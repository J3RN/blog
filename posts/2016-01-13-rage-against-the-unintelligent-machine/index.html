<!doctype html><html lang=en-us>
<head>
<title>Rage Against the Unintelligent Machine | J3RN's Blog</title>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content="&#34;Classical AI&#34; (fancy single-purpose algorithms) is still being taught in university AI courses. In this post I argue that computer science, as a field, should focus more on general AI and neuromorphic computing, while also noting ambiguity of the word &#34;intelligence.&#34;
">
<meta name=generator content="Hugo 0.88.0">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/css/style.css>
<link rel="shortcut icon" href=/images/favicon.ico type=image/x-icon>
<script defer data-domain=j3rn.com src=https://plausible.io/js/plausible.js></script>
</head>
<body>
<nav class=navigation>
<a href=/> <span class=arrow>‚Üê</span>Home</a>
<a href=/posts>Archive</a>
<a href=/tags>Tags</a>
<a class=button href=http://j3rn.com/index.xml>Subscribe</a>
</nav>
<main class=main>
<section id=single>
<h1 class=title>Rage Against the Unintelligent Machine</h1>
<div class=tip>
<time datetime="2016-01-13 10:08:00 -0500 -0500">Jan 13, 2016</time>
<span class=split>
¬∑
</span>
<span>
1385 words
</span>
<span class=split>
¬∑
</span>
<span>
7 minute read
</span>
</div>
<div class=content>
<p>Today marked the first time I was ever so uncomfortable in a class that I nearly got up and walked out. Such a level of discomfort is not so unfamiliar, though. It was, in fact, common during my review of candidates' projects during my involvement in one of my former employer&rsquo;s hiring process. Someone might ask the candidate something like &ldquo;How does user authorization work?&rdquo; They&rsquo;d drone on about encryption, throwing out buzzwords and waiting to see a spark in someone&rsquo;s eye, letting them know that they weren&rsquo;t a complete failure. It would never come. I would start getting jittery. I would feel an irrepressible urge to jump up and yell profanity, to tear out my hair and flip things.</p>
<p>It was like that, but in a university course. The professor started at the natural beginning, &ldquo;What is A.I.?&rdquo; A natural question that you would rather hope students would know the answer to as a prerequisite for taking the course. &ldquo;What,&rdquo; you might ask, &ldquo;<em>is</em> his definition of A.I.?&rdquo; A machine that need only behave intelligently.</p>
<blockquote>
<p>A machine that need only behave intelligently</p>
</blockquote>
<p>At this point, I shuffled uncomfortably in my chair. While this concept dates back to Dr. Alan Turing, a man widely considered the father of modern computing, this idea of a facade of intelligence with no real intelligent underpinnings disturbs me. Dr. Turing, as you may know, is widely known for creating the &ldquo;Turing Test,&rdquo; a common standard of intelligent behavior among A.I. researchers. To pass the Turing Test, a machine need only fool a human interrogator into believing that it is a human. Several programs, even rather trivial ones, have been able to pass this test from time to time. I do not believe these programs deserve the badge of &ldquo;intelligence,&rdquo; artificial or not.</p>
<blockquote>
<p>Several programs, even rather trivial ones, have been able to pass this test from time to time</p>
</blockquote>
<p>Let&rsquo;s say you disagree. Let&rsquo;s say that you think that there is no need to understand how a human brain (or otherwise) works in order to replicate its output. Fine, let&rsquo;s agree to disagree and move on. So you want to create a machine that will act &ldquo;intelligent.&rdquo; What is this &ldquo;intelligence&rdquo; anyway? Just on cue, the professor ever so slightly bumps the issue. He states something akin to:</p>
<blockquote>
<p>&ldquo;Intelligence is hard to define. For that reason, we don&rsquo;t. We just know intelligence when we see it. We can interact with a thing, and know that it is intelligent.&rdquo;</p>
</blockquote>
<p>I recoil in my seat. You think that you just <em>know</em> intelligence? You don&rsquo;t think you <em>might</em> want to have a destination in mind before starting to run full speed? It&rsquo;s really no wonder the A.I. field doesn&rsquo;t seem to have progressed since the 1950&rsquo;s! Why is it that we humans expect ourselves to be the arbiters of intelligence? Are we able to distinguish the intelligent from the unintelligent through some sixth sense? You may have already deduced this expectation of a human being able to judge intelligence from the Turing Test itself. As it turns out, not all humans are so intelligent. I had rather hoped that someone might have wondered &ldquo;If it must seem intelligent, shouldn&rsquo;t we try to actually define what that means?&rdquo; Evidently not.</p>
<p>Besides, what gave anyone the idea that being able to discern the intelligent from the unintelligent was a sufficient condition to be able to create A.I.? I can tell you if an object is or is not a car, but that doesn&rsquo;t qualify me to actually build one.</p>
<blockquote>
<p>Why is it that we humans expect ourselves to be the arbiters of intelligence?</p>
</blockquote>
<p>But wait! Here, the professor brings up a definition of intelligence from John McCarthy, a long-time A.I. researcher and the inventor of LISP. The quote is as follows:</p>
<blockquote>
<p>&ldquo;Intelligence is the computational part of the ability to achieve goals in the world.&rdquo;</p>
</blockquote>
<p>I think on this for a minute. My intuition tells me that this is utter rubbish, but I&rsquo;m not going to just blow off a quote by a major computer scientist on my intuition alone. Let&rsquo;s break this quote down.</p>
<blockquote>
<p>&ldquo;&mldr;the ability to achieve goals in the real world&rdquo;</p>
</blockquote>
<p>OK, sure. There&rsquo;s some goal that needs achieving. Like writing this blog post, catching a ball, holding a conversation, etc. How does intelligence fit in again?</p>
<blockquote>
<p>&ldquo;Intelligence is the computational part of&mldr;&rdquo;</p>
</blockquote>
<p>I considered this thoughtfully. Merriam-Webster defines &ldquo;computational&rdquo; in terms of &ldquo;compute&rdquo;, which it defines, in turn, as &ldquo;to find out (something) by using mathematical processes.&rdquo; What part of writing this blog post requires mathematical processes? What part of catching a ball or holding a conversation involves mathematical processes? It is true that you could write an algorithm to transform my notes from class (input) to this blog post (output), much like in Searle&rsquo;s <a href=http://plato.stanford.edu/entries/chinese-room/ target=_blank rel=noopener>Chinese Room</a>. But is that really &ldquo;acting intelligent?&rdquo; Would such an algorithm be able to create different blog posts for different inputs as a human would be able to? What if an entire life (a larger context) was fed as input as well?</p>
<blockquote>
<p>But is that really &ldquo;acting intelligent?&rdquo;</p>
</blockquote>
<p>At an abstract level, it seems somewhat believable. I believe that you could, perhaps, abstract the workings of the brain into a mathematical model, though it would be rather complex. I&rsquo;m not inclined, however, to believe that Dr. McCarthy and I agree on a level of abstraction. Besides, A.I. researchers don&rsquo;t care about real intelligence, and thus brains, anyway, remember?</p>
<p>Suddenly, things took a turn for the worse. The professor gave forth the reasoning for &ldquo;Weak A.I.&rdquo; (just trying to emulate output) over &ldquo;Strong A.I.&rdquo; (simulating a brain, or brain-like functions): Brains are complex. Frankly, this goes without saying. If brains were simple, there would be some sort of concensus over how they work at a variety of levels, which there certainly is not.</p>
<blockquote>
<p>Brains are complex</p>
</blockquote>
<p>However, as an excuse for not attempting to understand or replicate the inner workings of brains in the pursuit of intelligent behavior, this idea is ludicrous. To imagine that replicating each of millions of features of a brain, separately, using disparate mathematical methods is <em>simpler</em> than trying to learn from nature is preposterous. Don&rsquo;t believe me? Let&rsquo;s look at an example. Let&rsquo;s say you have a chess-playing program that operates by classical A.I. methods: the application of various clever data structures and algorithms. Sure, it plays chess well enough to beat a world champion. Congratulations! But what if I wanted to play checkers against it instead? The rules of checkers are quite different from those of chess, so I imagine that to add some world-class checkers-playing ability while retaining your program&rsquo;s chess-playing skill, you&rsquo;ll have to add some complexity to your code base. What if I wanted it to pass the Turing Test too? What if I wanted it to catch a ball? Or write a blog post? Suddenly, we are awash in compounding complexity.</p>
<blockquote>
<p>But what if I wanted to play checkers against it instead?</p>
</blockquote>
<p>I suppose the my final cringe came when I saw a quote from Dr. Ray Kurzweil appear in the professor&rsquo;s presentation. I am rather sure that Dr. Kurzweil would be ashamed to appear amongst such rubbish. I will not go into detail here, but Dr. Kurzweil&rsquo;s methods of creating intelligent computer programs are far from the &ldquo;forget brains and just throw algorithms at the problem&rdquo; approach. In case you are interested in learning more about his work, I have included a link to his book &ldquo;How to Create a Mind&rdquo; below.</p>
<p>Perhaps what really disturbed me was that this class appears to be exactly what I was afraid it would be. In the beginning of his masterful work &ldquo;On Intelligence,&rdquo; Jeff Hawkins lays out the history of the A.I. movement and critiques its fallacies and shortcomings. What Hawkins witnessed was the A.I. movement in the 1980&rsquo;s, and, evidently, it hasn&rsquo;t changed at all since.</p>
<h2 id=resources>Resources <a href=#resources class=anchor>üîó</a></h2><p><strong>If you are interested in researching a different, more brain-centric view of creating intelligent computer programs, or simply think that it would be nice to have a definition of what intelligence is before attempting to create it, I encourage you to read the books below.</strong></p>
<ul>
<li><a href=http://www.amazon.com/Intelligence-Jeff-Hawkins/dp/0805078533/ target=_blank rel=noopener>On Intelligence</a> by <a href=https://en.wikipedia.org/wiki/Jeff_Hawkins target=_blank rel=noopener>Jeff Hawkins</a>.</li>
<li><a href=http://numenta.org/resources/HTM_CorticalLearningAlgorithms.pdf target=_blank rel=noopener>Numenta White Paper</a> supplimenting the above text (direct link).</li>
<li><a href=http://www.amazon.com/How-Create-Mind-Thought-Revealed/dp/1491518839 target=_blank rel=noopener>How to Create a Mind</a> by <a href=http://www.kurzweilai.net/ray-kurzweil-biography target=_blank rel=noopener>Dr. Ray Kurzweil</a>.</li>
</ul>
</div>
<div class=tags>
<a href=http://j3rn.com/tags/ai>ai</a>
<a href=http://j3rn.com/tags/machine-learning>machine learning</a>
</div>
</section>
</main>
<footer id=footer>
<div id=social>
<a class=symbol href=https://github.com/J3RN rel=me target=_blank><svg fill="#bbb" width="28" height="28" viewBox="0 0 72 72" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Github</title><desc>Created with Sketch.</desc><defs/><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Social-Icons---Rounded-Black" transform="translate(-264.000000, -939.000000)"><g id="Github" transform="translate(264.000000, 939.000000)"><path d="M8 72H64c4.418278.0 8-3.581722 8-8V8c0-4.418278-3.581722-8-8-8H8c-4.418278 811624501e-24-8 3.581722-8 8V64c541083001e-24 4.418278 3.581722 8 8 8z" id="Rounded" fill="#bbb"/><path d="M35.9985 13C22.746 13 12 23.7870921 12 37.096644c0 10.6440272 6.876 19.6751861 16.4145 22.8617681C29.6145 60.1797862 30.0525 59.4358488 30.0525 58.7973276 30.0525 58.2250681 30.0315 56.7100863 30.0195 54.6996482c-6.6765 1.4562499-8.085-3.2302544-8.085-3.2302544-1.0905-2.7829884-2.664-3.5239139-2.664-3.5239139C17.091 46.4500754 19.4355 46.4801943 19.4355 46.4801943c2.4075.1701719 3.675 2.4833051 3.675 2.4833051 2.142 3.6820383 5.6175 2.6188404 6.9855 2.0014024C30.3135 49.4077535 30.9345 48.3460615 31.62 47.7436831 26.2905 47.1352808 20.688 45.0691228 20.688 35.8361671c0-2.6308879.9345-4.781379 2.4705-6.4665327C22.911 28.7597262 22.0875 26.3110578 23.3925 22.9934585c0 0 2.016-.6475568 6.6 2.4697516C31.908 24.9285993 33.96 24.6620468 36.0015 24.6515052 38.04 24.6620468 40.0935 24.9285993 42.0105 25.4632101c4.581-3.1173084 6.5925-2.4697516 6.5925-2.4697516C49.9125 26.3110578 49.089 28.7597262 48.8415 29.3696344 50.3805 31.0547881 51.309 33.2052792 51.309 35.8361671c0 9.2555448-5.6115 11.29309-10.9575 11.8894446.860999999999997.7439374 1.629 2.2137408 1.629 4.4621184C41.9805 55.4089489 41.9505 58.0067059 41.9505 58.7973276 41.9505 59.4418726 42.3825 60.1918338 43.6005 59.9554002 53.13 56.7627944 60 47.7376593 60 37.096644 60 23.7870921 49.254 13 35.9985 13" fill="#fff"/></g></g></g></svg>
</a>
</div>
<div class=copyright>
¬© Copyright
2021
<span class=split><svg fill="#bbb" width="15" height="15" id="heart-15" xmlns="http://www.w3.org/2000/svg" width="15" height="15" viewBox="0 0 15 15"><path d="M13.91 6.75c-1.17 2.25-4.3 5.31-6.07 6.94-.1903.1718-.4797.1718-.67.0C5.39 12.06 2.26 9 1.09 6.75-1.48 1.8 5-1.5 7.5 3.45 10-1.5 16.48 1.8 13.91 6.75z"/></svg>
</span>
Jonathan Arnett
</div>
<div class=powerby>
Powered by <a href=http://www.gohugo.io/>Hugo</a> Theme By <a href=https://github.com/nodejh/hugo-theme-cactus-plus>nodejh</a>
</div>
</footer>
</body>
</html>